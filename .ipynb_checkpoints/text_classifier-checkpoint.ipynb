{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f4d4ac4-a1c2-40af-8aeb-d7f3026989c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6099dcde-53b4-4251-890a-98c8296ee170",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_dict = {'yelp':   'data/sentiment_analysis/yelp_labelled.txt',\n",
    "                 'amazon': 'data/sentiment_analysis/amazon_cells_labelled.txt',\n",
    "                 'imdb':   'data/sentiment_analysis/imdb_labelled.txt'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edfddec-500c-42af-a238-f276f79ff568",
   "metadata": {},
   "source": [
    "this block is just for reading the txt files, spearate the sentences from the labels using \\t, with this, we create two columns, the third one is an indicator of from where the review came, which is the source column, then we concatinated them to df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fb56a9e-34dc-468b-808f-812d1ccbe1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "for source, filepath in filepath_dict.items():\n",
    "    df = pd.read_csv(filepath, names=['sentence', 'label'], sep='\\t')\n",
    "    df['source'] = source\n",
    "    df_list.append(df)\n",
    "df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10206ea6-2c65-4e0d-b0aa-4443c125f2a7",
   "metadata": {},
   "source": [
    "now, we vectorize sentences. It takes the words of each sentence and creates a vocabulary of all the unique words in the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9557ef61-14f7-4bdc-a66f-5f78add12f46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'John': 0, 'likes': 5, 'ice': 4, 'cream': 2, 'hates': 3, 'chocolate': 1}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = ['John likes ice cream', 'John hates chocolate']\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(min_df=0, lowercase=False)\n",
    "vectorizer.fit(sentences)\n",
    "vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "532101d3-8f64-4777-ab5b-5000274b5cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1, 0, 1, 1],\n",
       "       [1, 1, 0, 1, 0, 0]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform(sentences).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf5b767-35ac-466f-82e6-fffdea5d877f",
   "metadata": {},
   "source": [
    "now we start with the lab requierment, defining a baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd1488d-0ec9-4526-bb06-a6c109157344",
   "metadata": {},
   "source": [
    "let's start by testing one of the models (yelp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9180c346-57a0-4fc4-9c9d-1bdd57b10bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3f242e4-a294-46c7-aea8-d68c6d7f631e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yelp = df[df['source'] == 'yelp']\n",
    "sentences = df_yelp['sentence'].values\n",
    "y = df_yelp['label'].values\n",
    "sentences_train, sentences_test, y_train, y_test = train_test_split(sentences, y, test_size=0.25, random_state=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec6b297-737b-45d4-bdc0-6c0d014dd560",
   "metadata": {},
   "source": [
    "now to vectorize our sentences, we need to do this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "127bb5b4-b8f1-4008-b8d7-111e8c1adb93",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "vectorizer.fit(sentences_train)\n",
    "X_train = vectorizer.transform(sentences_train)\n",
    "X_test  = vectorizer.transform(sentences_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bb3fbd-0bd8-4439-b16a-d325bfa8b2a8",
   "metadata": {},
   "source": [
    "final step for the baseline model is the  logistic regression , in order to create our model and check it's acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd5cf534-73bb-49c1-832f-6885369df40a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79.60000000000001"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "score = classifier.score(X_test, y_test)\n",
    "score*100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb88f3e-e0c0-43d2-8bc4-992aca91c373",
   "metadata": {},
   "source": [
    "and now, we apply these steps for all the reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0de3ab22-5c13-4756-8c30-5cb33aec156e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for yelp data: 0.7960\n",
      "Accuracy for amazon data: 0.7960\n",
      "Accuracy for imdb data: 0.7487\n"
     ]
    }
   ],
   "source": [
    "for source in df['source'].unique():\n",
    "    df_source = df[df['source'] == source]\n",
    "    sentences = df_source['sentence'].values\n",
    "    y = df_source['label'].values\n",
    "\n",
    "    sentences_train, sentences_test, y_train, y_test = train_test_split(\n",
    "        sentences, y, test_size=0.25, random_state=1000)\n",
    "\n",
    "    vectorizer = CountVectorizer()\n",
    "    vectorizer.fit(sentences_train)\n",
    "    X_train = vectorizer.transform(sentences_train)\n",
    "    X_test  = vectorizer.transform(sentences_test)\n",
    "\n",
    "    classifier = LogisticRegression()\n",
    "    classifier.fit(X_train, y_train)\n",
    "    score = classifier.score(X_test, y_test)\n",
    "    print('Accuracy for {} data: {:.4f}'.format(source, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ee5575-e3e7-45f5-86d9-b330c43ff5ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
